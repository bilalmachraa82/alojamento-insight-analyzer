# Manual Testing Guide

## Overview
This guide walks you through end-to-end testing of the Alojamento Insight Analyzer platform to ensure everything is working correctly before production launch.

---

## Prerequisites

‚úÖ **Before you start:**
- [ ] All environment variables are set (see [README.md](../README.md#1-environment-variables))
- [ ] Database migrations are applied (`supabase db push`)
- [ ] Edge function secrets are configured
- [ ] Apify actors are installed in your account
- [ ] Development server is running (`npm run dev`)

---

## Test Suite 1: Local Development Stack

### 1.1 Environment Setup
```bash
# Clone and install
git clone <repo-url>
cd <project-folder>
npm install

# Copy environment file
cp .env.example .env
# Fill in: VITE_SUPABASE_URL, VITE_SUPABASE_PUBLISHABLE_KEY, VITE_SUPABASE_PROJECT_ID
```

**Expected Result:**
- ‚úÖ No errors during `npm install`
- ‚úÖ `.env` file exists with all required variables

### 1.2 Quality Gates
```bash
# Type checking
npm run typecheck

# Linting
npm run lint

# Build
npm run build
```

**Expected Result:**
- ‚úÖ No TypeScript errors
- ‚úÖ No ESLint errors
- ‚úÖ Build completes successfully with dist/ folder created

### 1.3 Development Server
```bash
npm run dev
```

**Expected Result:**
- ‚úÖ Server starts on http://localhost:5173
- ‚úÖ No console errors in terminal
- ‚úÖ Homepage loads without errors

---

## Test Suite 2: Diagnostic Form Submission

### 2.1 Valid Airbnb URL
**Test Case:** Submit a valid Airbnb property URL

**Steps:**
1. Go to http://localhost:5173
2. Fill form:
   - Name: `Test User`
   - Email: `test@example.com`
   - Platform: `Airbnb`
   - URL: `https://www.airbnb.com/rooms/12345678`
3. Submit form

**Expected Result:**
- ‚úÖ Toast appears: "Diagn√≥stico enviado com sucesso!"
- ‚úÖ Success page shows or loading indicator appears
- ‚úÖ Check Supabase dashboard ‚Üí Table Editor ‚Üí `diagnostic_submissions`:
  - New row exists
  - `status` = `pending` or `processing`
  - `platform` = `airbnb`

**Screenshots to capture:**
- [ ] Form filled out
- [ ] Success toast
- [ ] Supabase table with new row

---

### 2.2 Valid Booking.com URL
**Test Case:** Submit a valid Booking.com hotel URL

**Steps:**
1. Go to homepage
2. Fill form:
   - Name: `Test User 2`
   - Email: `test2@example.com`
   - Platform: `Booking.com`
   - URL: `https://www.booking.com/hotel/pt/example-hotel.html`
3. Submit form

**Expected Result:**
- ‚úÖ Success toast appears
- ‚úÖ New row in `diagnostic_submissions` with status `pending`/`processing`

---

### 2.3 Invalid Booking.com Share URL (Should Fail)
**Test Case:** Submit a Booking.com share link (should be blocked)

**Steps:**
1. Go to homepage
2. Fill form:
   - URL: `https://www.booking.com/Share-abc123`
3. Submit form

**Expected Result:**
- ‚úÖ Toast appears: "‚ö†Ô∏è Link Encurtado N√£o Permitido"
- ‚úÖ Description explains to use full URL
- ‚úÖ Form submission is blocked (no new row in database)
- ‚úÖ Toast visible for 8 seconds

**Screenshot:**
- [ ] Error toast with correct message

---

### 2.4 Invalid Booking.com URL (Missing /hotel/)
**Test Case:** Submit Booking.com URL without `/hotel/` path

**Steps:**
1. Fill form with: `https://www.booking.com/searchresults.html?...`
2. Submit

**Expected Result:**
- ‚úÖ Toast: "‚ö†Ô∏è URL do Booking.com Inv√°lido"
- ‚úÖ Message explains URL must contain '/hotel/'
- ‚úÖ No database row created

---

### 2.5 Malformed URL
**Test Case:** Submit completely invalid URL

**Steps:**
1. Fill form with: `not-a-url`
2. Submit

**Expected Result:**
- ‚úÖ Form validation error appears (HTML5 or custom validation)
- ‚úÖ Form does not submit

---

## Test Suite 3: Edge Functions Pipeline

### 3.1 Process Diagnostic Function
**Test Case:** Verify `process-diagnostic` edge function starts Apify scraping

**Steps:**
1. Submit a valid Booking.com URL (see Test 2.2)
2. Go to Supabase dashboard ‚Üí Edge Functions ‚Üí Logs
3. Filter to `process-diagnostic`
4. Check logs for the submission ID

**Expected Result:**
- ‚úÖ Log: "Processing diagnostic submission: {id}"
- ‚úÖ Log: "Processing URL: {url}"
- ‚úÖ Log: "Starting Apify scraping process"
- ‚úÖ Log: "Property data collection started"
- ‚úÖ Response: `{"success":true,"runId":"...","actorId":"..."}`

**If logs show error:**
- ‚ùå "Missing submission ID" ‚Üí Check form submission
- ‚ùå "Missing environment variables" ‚Üí Check `APIFY_API_TOKEN` in edge function secrets
- ‚ùå "Booking.com share URL detected" ‚Üí Expected for test 2.3, issue if seen for valid URL

---

### 3.2 Check Scrape Status Function
**Test Case:** Verify Apify scraping completes and data is processed

**Steps:**
1. Wait 30-60 seconds after submission
2. Go to Supabase dashboard ‚Üí Edge Functions ‚Üí `check-scrape-status` ‚Üí Logs
3. Look for logs related to your submission ID

**Expected Result:**
- ‚úÖ Log: "Processing Voyager Booking Reviews data" (or similar)
- ‚úÖ Log: "Processed property info: {...}"
- ‚úÖ Log: "Triggering Claude analysis for submission: {id}"
- ‚úÖ Database update: `status` ‚Üí `scraping_completed`
- ‚úÖ Database: `property_data` JSON field populated

**Check in Supabase Table Editor:**
```sql
SELECT id, status, property_data, updated_at
FROM diagnostic_submissions
WHERE id = '{your-submission-id}'
ORDER BY updated_at DESC;
```

**Expected `property_data` structure:**
```json
{
  "property_data": {
    "property_name": "Example Hotel",
    "location": "Lisbon, Portugal",
    "rating": 4.5,
    "review_count": 123,
    "reviews": [...]
  },
  "completed_at": "2025-10-16T14:30:00Z"
}
```

---

### 3.3 Analyze Property Claude Function
**Test Case:** Verify Claude AI analysis completes

**Steps:**
1. Wait 1-2 minutes after scraping completes
2. Check `analyze-property-claude` logs
3. Look for your submission ID

**Expected Result:**
- ‚úÖ Log: "Analyzing property data with Claude for submission: {id}"
- ‚úÖ Log: "Sending request to Claude API"
- ‚úÖ Log: "Received response from Claude API"
- ‚úÖ Log: "Successfully parsed Claude analysis JSON"
- ‚úÖ Log: "Updating submission with Claude analysis results"
- ‚úÖ Log: "Triggering premium PDF generation for submission: {id}"
- ‚úÖ Database: `status` ‚Üí `completed`
- ‚úÖ Database: `analysis_result` JSON field populated

**Check in database:**
```sql
SELECT id, status, analysis_result, updated_at
FROM diagnostic_submissions
WHERE id = '{your-submission-id}';
```

**Expected `analysis_result` structure:**
```json
{
  "health_score": {
    "total": 75,
    "breakdown": {...},
    "categoria": "bom"
  },
  "diagnostico_inicial": {...},
  "reputacao_reviews": {...},
  "kpis_acompanhamento": {...}
}
```

**If Claude analysis fails:**
- ‚ùå "Missing required environment variables" ‚Üí Check `CLAUDE_API_KEY`
- ‚ùå "No property data found" ‚Üí Scraping failed, check previous step
- ‚ùå HTTP 401 from Claude ‚Üí API key invalid
- ‚ùå HTTP 429 from Claude ‚Üí Rate limit exceeded, wait and retry

---

### 3.4 Generate Premium PDF Function
**Test Case:** Verify HTML report generation

**Steps:**
1. After Claude analysis completes, check `generate-premium-pdf` logs
2. Look for your submission ID

**Expected Result:**
- ‚úÖ Log: "Generating premium PDF for submission: {id}"
- ‚úÖ Log: "HTML generated successfully, size: {X} bytes"
- ‚úÖ Log: "Premium report generated successfully"
- ‚úÖ Database: `premium_report_url` field populated
- ‚úÖ Database: `report_generated_at` timestamp set

**Check in database:**
```sql
SELECT id, premium_report_url, report_generated_at
FROM diagnostic_submissions
WHERE id = '{your-submission-id}';
```

**Test PDF access:**
1. Copy the `premium_report_url` from database
2. Open in browser (incognito mode to test public access)
3. Verify HTML report loads with all sections

**Expected Report Sections:**
- ‚úÖ Property name in header
- ‚úÖ Health Score circle with number
- ‚úÖ Diagn√≥stico Inicial section
- ‚úÖ Reputa√ß√£o & Reviews section
- ‚úÖ Estrat√©gia de Pre√ßos table
- ‚úÖ KPIs & Acompanhamento section

**If PDF generation fails:**
- ‚ùå "Bucket not found" ‚Üí Run storage migration or create bucket manually
- ‚ùå "Row level security policy violation" ‚Üí Check RLS policies on storage.objects
- ‚ùå Report URL is 404 ‚Üí Bucket not public or file wasn't uploaded

---

## Test Suite 4: Results Page Experience

### 4.1 View Pending/Processing Submission
**Test Case:** View results page while analysis is in progress

**Steps:**
1. Submit a new diagnostic (get submission ID from database or URL)
2. Go to: `http://localhost:5173/results/{submission-id}`

**Expected Result:**
- ‚úÖ Header shows: "An√°lise da Propriedade"
- ‚úÖ Property name displayed (or "Propriedade" if not yet scraped)
- ‚úÖ Processing status component shows:
  - "An√°lise em Andamento"
  - Progress bar animating
  - Current status message (e.g., "Recolhendo dados da propriedade...")
- ‚úÖ Refresh button visible
- ‚úÖ Clicking refresh updates status

---

### 4.2 View Completed Submission (Basic View)
**Test Case:** View completed analysis without premium report

**Steps:**
1. Go to results page for a completed submission
2. Verify all sections render

**Expected Result:**
- ‚úÖ Property name, location, type displayed
- ‚úÖ Rating shown (‚≠ê X / 5)
- ‚úÖ Performance metrics section shows data
- ‚úÖ Recommendations list rendered
- ‚úÖ Pricing strategy table displayed
- ‚úÖ Competitor analysis visible
- ‚úÖ "Upgrade to Premium" CTA appears (if using mock data)

---

### 4.3 View Premium Submission
**Test Case:** View completed analysis with premium report

**Steps:**
1. Go to results page for submission with `premium_report_url`
2. Check for premium report viewer

**Expected Result:**
- ‚úÖ "Download Premium Report" button visible
- ‚úÖ Clicking button opens report in new tab
- ‚úÖ Enhanced KPI sections show real data (not mocked)

---

### 4.4 View Manual Review Status
**Test Case:** View submission marked for manual review

**Steps:**
1. Submit a URL that will trigger manual review (e.g., unsupported platform)
2. Go to results page

**Expected Result:**
- ‚úÖ Yellow warning icon ‚ö†Ô∏è
- ‚úÖ Message: "Precisamos da sua ajuda"
- ‚úÖ Explanation of why manual review is needed
- ‚úÖ Button: "Solicitar an√°lise manual"
- ‚úÖ Alternative button: "Tentar com outro link"

---

### 4.5 Request Manual Analysis
**Test Case:** Trigger manual review request

**Steps:**
1. On a manual review page, click "Solicitar an√°lise manual"

**Expected Result:**
- ‚úÖ Toast: "Solicita√ß√£o enviada"
- ‚úÖ Database: `status` ‚Üí `manual_review_requested`
- ‚úÖ Page refreshes after 1 second
- ‚úÖ Button disappears, message updates to: "Seu pedido de an√°lise manual foi registrado"

---

## Test Suite 5: Premium PDF Test Page

### 5.1 Generate PDF for Existing Submission
**Test Case:** Use `/test-pdf` page to regenerate report

**Steps:**
1. Go to: `http://localhost:5173/test-pdf`
2. Enter a submission ID with completed analysis
3. Click "Gerar PDF"

**Expected Result:**
- ‚úÖ Loading indicator appears
- ‚úÖ Toast: "PDF Gerado com Sucesso!"
- ‚úÖ Green alert box with download link appears
- ‚úÖ Clicking link opens report in new tab
- ‚úÖ Report loads correctly with all data

---

### 5.2 Test with Latest Completed Submission
**Test Case:** Auto-select most recent completed submission

**Steps:**
1. Go to `/test-pdf`
2. Click "Testar com √öltima Submiss√£o Completa"

**Expected Result:**
- ‚úÖ System finds most recent completed submission
- ‚úÖ Submission ID field auto-populates
- ‚úÖ PDF generates successfully
- ‚úÖ Toast shows submission ID used

---

### 5.3 Error Handling - No Analysis
**Test Case:** Try to generate PDF for submission without analysis

**Steps:**
1. Go to `/test-pdf`
2. Enter ID of pending submission (no `analysis_result`)
3. Click "Gerar PDF"

**Expected Result:**
- ‚úÖ Error toast: "Erro ao Gerar PDF"
- ‚úÖ Description: "Esta submiss√£o ainda n√£o tem an√°lise completa"

---

## Test Suite 6: Database & KPI System

### 6.1 Daily Ingest Function
**Test Case:** Manually trigger data ingestion

**Steps:**
1. Ensure you have at least one completed submission
2. Go to Supabase dashboard ‚Üí SQL Editor
3. Run:
   ```sql
   SELECT net.http_post(
     url := 'https://your-project.supabase.co/functions/v1/daily-ingest',
     headers := jsonb_build_object(
       'Authorization',
       'Bearer ' || current_setting('app.settings.service_role_key')
     )
   );
   ```

**Expected Result:**
- ‚úÖ Function returns success response
- ‚úÖ `daily-ingest` logs show:
  - "Starting daily-ingest process..."
  - "Found X submissions to process"
  - "Successfully processed submission {id} for property {property_id}"
  - "Refreshing KPI views..."
  - "KPI views refreshed successfully"

**Check fact tables populated:**
```sql
-- Check fact_daily
SELECT * FROM fact_daily ORDER BY date DESC LIMIT 10;

-- Check fact_channel_daily
SELECT * FROM fact_channel_daily ORDER BY date DESC LIMIT 10;

-- Check dim_property
SELECT * FROM dim_property LIMIT 10;
```

**Expected:**
- ‚úÖ New rows in `fact_daily` with today's date
- ‚úÖ New rows in `fact_channel_daily` distributed across channels
- ‚úÖ New rows in `dim_property` (one per processed submission)

---

### 6.2 KPI Views
**Test Case:** Verify materialized views are updated

**Steps:**
```sql
-- Check KPI daily
SELECT * FROM kpi_daily ORDER BY date DESC LIMIT 5;

-- Check KPI aggregated
SELECT * FROM kpi_aggregated LIMIT 5;

-- Check KPI comp set daily
SELECT * FROM kpi_comp_set_daily ORDER BY date DESC LIMIT 5;
```

**Expected Result:**
- ‚úÖ All views return data
- ‚úÖ Calculations look reasonable (no negative revenues, occupancy 0-100%, etc.)
- ‚úÖ Date ranges match fact table data

---

## Test Suite 7: Security & RLS

### 7.1 Anon Key Cannot Write to Protected Tables
**Test Case:** Verify RLS prevents unauthorized writes

**Steps:**
1. Get your Supabase anon key from dashboard
2. Try to insert directly into `fact_daily`:
   ```bash
   curl -X POST "https://your-project.supabase.co/rest/v1/fact_daily" \
     -H "apikey: {ANON_KEY}" \
     -H "Authorization: Bearer {ANON_KEY}" \
     -H "Content-Type: application/json" \
     -d '{
       "property_id": "00000000-0000-0000-0000-000000000000",
       "date": "2025-10-16",
       "rooms_available": 1,
       "rooms_sold": 1,
       "room_revenue": 100,
       "total_revenue": 100
     }'
   ```

**Expected Result:**
- ‚úÖ HTTP 403 or 401 error
- ‚úÖ Error message: "new row violates row-level security policy" or similar

---

### 7.2 Storage Bucket Public Read
**Test Case:** Verify premium reports are publicly readable

**Steps:**
1. Get a `premium_report_url` from database
2. Open in incognito browser (unauthenticated)

**Expected Result:**
- ‚úÖ Report loads successfully
- ‚úÖ No authentication required

---

### 7.3 Storage Bucket Cannot Be Written Without Service Role
**Test Case:** Verify anon key cannot upload to storage

**Steps:**
```bash
curl -X POST "https://your-project.supabase.co/storage/v1/object/premium-reports/test.html" \
  -H "Authorization: Bearer {ANON_KEY}" \
  -H "Content-Type: text/html" \
  -d "<html><body>Test</body></html>"
```

**Expected Result:**
- ‚úÖ HTTP 403 error
- ‚úÖ Error: "row-level security policy violation" or "not authorized"

---

## Test Suite 8: Error Recovery & Edge Cases

### 8.1 Reprocess Stuck Submission
**Test Case:** Use `reprocess-submission` function to retry failed submission

**Steps:**
1. Find a stuck submission (status = `processing` for > 30 min)
2. Go to Supabase SQL Editor
3. Run:
   ```sql
   SELECT net.http_post(
     url := 'https://your-project.supabase.co/functions/v1/reprocess-submission',
     headers := jsonb_build_object('Authorization', 'Bearer ' || current_setting('app.settings.service_role_key')),
     body := jsonb_build_object('submissionId', '{stuck-submission-id}')
   );
   ```

**Expected Result:**
- ‚úÖ Function returns success
- ‚úÖ `process-diagnostic` function is triggered again
- ‚úÖ Submission status resets to `processing`
- ‚úÖ Pipeline runs from start

---

### 8.2 Handle Missing Environment Variables Gracefully
**Test Case:** Verify edge functions fail fast with clear error

**Steps:**
1. Temporarily remove `APIFY_API_TOKEN` from edge function secrets
2. Submit a new diagnostic
3. Check logs

**Expected Result:**
- ‚úÖ Log: "‚ùå Missing required environment variables: APIFY_API_TOKEN"
- ‚úÖ Log shows instructions on how to fix
- ‚úÖ Function returns HTTP 500 with clear error message
- ‚úÖ No silent failure

---

## Test Suite 9: CI/CD Workflow

### 9.1 GitHub Actions
**Test Case:** Verify CI workflow runs on push

**Steps:**
1. Make a small code change (e.g., add comment to README)
2. Commit and push to GitHub
3. Go to: https://github.com/{your-repo}/actions
4. Check latest workflow run

**Expected Result:**
- ‚úÖ Workflow triggers automatically
- ‚úÖ All jobs pass:
  - ‚úÖ Checkout repository
  - ‚úÖ Setup Node.js
  - ‚úÖ Install dependencies
  - ‚úÖ Type check
  - ‚úÖ Lint
- ‚úÖ Green checkmark on commit in GitHub

---

## Summary Checklist

After completing all test suites, verify:

- [ ] **Local stack works** - npm install, typecheck, lint, build, dev all succeed
- [ ] **Form validation works** - Invalid URLs blocked with clear messages
- [ ] **Edge functions work** - All 4 main functions execute without errors
- [ ] **Scraping works** - Apify returns property data successfully
- [ ] **AI analysis works** - Claude returns structured JSON analysis
- [ ] **PDF generation works** - HTML reports generate and are publicly accessible
- [ ] **Results page works** - All states (pending, processing, completed, manual review) render correctly
- [ ] **KPI system works** - Daily ingest populates fact tables and refreshes views
- [ ] **Security works** - RLS prevents unauthorized access, storage bucket has correct policies
- [ ] **Error handling works** - Failed submissions show helpful messages, stuck submissions can be reprocessed
- [ ] **CI/CD works** - GitHub Actions runs successfully on every push

---

## Reporting Issues

If any test fails:

1. **Capture evidence:**
   - Screenshot of error
   - Console logs (browser + edge function)
   - Database state (relevant table rows)
   - Network requests (if applicable)

2. **Document steps to reproduce:**
   - What test were you running?
   - What was the exact input?
   - What happened vs what should have happened?

3. **Check common fixes:**
   - Is `.env` configured correctly?
   - Are edge function secrets set in Supabase dashboard?
   - Are database migrations applied?
   - Is storage bucket created?

4. **File issue on GitHub** with all evidence and reproduction steps

---

## Next Steps After Testing

Once all tests pass:
1. ‚úÖ Review [README.md](../README.md) production checklist
2. ‚úÖ Set up monitoring (track success/failure rates)
3. ‚úÖ Configure cron for `daily-ingest`
4. ‚úÖ Deploy to production via Lovable
5. ‚úÖ Run smoke tests in production
6. ‚úÖ Set up alerting for stuck submissions

üéâ **Your platform is ready for launch!**
